---
title: 2025 å¹´ 8 æœˆæ–‡æ‘˜
date: 2025-08-01
lastmod: 2025-08-31
---

## [Slow](https://michaelnotebook.com/slow/index.html)

> What problems can human beings only solve over a very long period of time? And how can we build institutions that solve those problems?

## [Reflections on Palantir](https://nabeelqu.substack.com/p/reflections-on-palantir) â­

> If you wanted to work on these â€˜harderâ€™ areas of the economy but also wanted a Silicon Valley work culture, Palantir was basically your only option for awhile.

> In general, as I begin to survey more startups, I find that the talent level at PayPal is not uncommon for a Silicon Valley startup, but the differentiating factor may have been the level of intensity from the top: both Peter Thiel and Max Levchin were extremely intense people - hyper-competitive, hard-working, and unwilling to accept defeat. I think this sort of leadership is what pushes the "standard" talented team to be able to do great things and, subsequently, contributes to producing a wellspring of later achievements.

> Palantir was an unusually intense and weird place. I remember my first time I talked to Stephen Cohen he had the A/C in his office set at 60, several weird-looking devices for minimizing CO2 content in the room, and had a giant pile of ice in a cup.

> I like to meet candidates with no data about them: no rÃ©sumÃ©, no preliminary discussions or job description, just the candidate and me in a room. I ask a fairly random question, one that is orthogonal to anything they would be doing at Palantir. I then watch how they disaggregate the question, if they appreciate how many different ways there are to see the same thing. I like to keep interviews short, about 10 minutes. Otherwise, people move into their learned responses and you donâ€™t get a sense of who they really are.

> many people have copied the â€˜hardcoreâ€™ working culture and the â€˜this is the Marinesâ€™ vibe, but few have the intellectual atmosphere, the sense of being involved in a rich set of ideas. This is hard to LARP - your founders and early employees have to be genuinely interesting intellectual thinkers.

> When I joined, Palantir was divided up into two types of engineers:
>
> Engineers who work with customers, sometimes known as FDEs, forward deployed engineers.
>
> Engineers who work on the core product team (product development - PD), and rarely go visit customers.
>
> ...
> This made the software hard to describe concisely - it wasnâ€™t just a database or a spreadsheet, it was an end-to-end solution to that specific problem, and to hell with generalizability. Your job was to solve the problem, and not worry about overfitting; PDâ€™s job was to take whatever youâ€™d built and generalize it, with the goal of selling it elsewhere.
> ...
> FDEs tend to write code that gets the job done fast, which usually means â€“ politely â€“ technical debt and hacky workarounds. PD engineers write software that scales cleanly, works for multiple use cases, and doesnâ€™t break. One of the key â€˜secretsâ€™ of the company is that generating deep, sustaining enterprise value requires both.

> Tyler Cowen has a wonderful saying, â€˜context is that which is scarceâ€™, and you could say itâ€™s the foundational insight of this model.

> Why is data integration so hard? The data is often in different formats that arenâ€™t easily analyzed by computers â€“ PDFs, notebooks, Excel files (my god, so many Excel files) and so on. But often what really gets in the way is organizational politics: a team, or group, controls a key data source, the reason for their existence is that they are the gatekeepers to that data source, and they typically justify their existence in a corporation by being the gatekeepers of that data source (and, often, providing analyses of that data).

> The overall â€˜vibeâ€™ of the company was more of a messianic cult than a normal software company. But importantly, it seemed that criticism was highly tolerated and welcomed â€“ one person showed me an email chain where an entry-level software engineer was having an open, contentious argument with a Director of the company with the entire company (around a thousand people) ccâ€™d. As a rationalist-brained philosophy graduate, this particular point was deeply important to me â€“ I wasnâ€™t interested in joining an uncritical cult. But a cult of skeptical people who cared deeply and wanted to argue about where the world was going and how software fit into it â€“ existentially â€“ that was interesting to me.

> Iâ€™m not sure if they still do this, but at the time when you joined they sent you a copy of Impro, The Looming Tower (9/11 book), Interviewing Users, and Getting Things Done. I also got an early PDF version of what became Ray Dalioâ€™s Principles.
> ...
> But why Impro?
> ...
> Impro is popular with nerds partly because it breaks down social behavior mechanistically.

> One of my favorite insights from Tyler Cowenâ€™s book â€˜Talentâ€™ is that the most talented people tend to develop their own vocabularies and memes, and these serve as entry points to a whole intellectual world constructed by that person. Tyler himself is of course a great example of this. Any MR reader can name 10+ Tylerisms instantly - â€˜model thisâ€™, â€˜context is that which is scarceâ€™, â€˜solve for the equilibriumâ€™, â€˜the great stagnationâ€™ are all examples. You can find others who are great at this. Thiel is one. Elon is another (â€œmultiplanetary speciesâ€, â€œpreserving the light of consciousnessâ€, etc. are all memes). Trump, Yudkowsky, gwern, SSC, Paul Graham, all of them regularly coin memes. It turns out that this is a good proxy for impact.
>
> This insight goes for companies, too, and Palantir had its own, vast set of terms, some of which are obscure enough that â€œwhat does Palantir actually do?â€ became a meme online. â€˜Ontologyâ€™ is an old one, but then there is â€˜implâ€™, â€˜artistâ€™s colonyâ€™, â€˜compoundingâ€™, â€˜the 36 chambersâ€™, â€˜dotsâ€™, â€˜metabolizing painâ€™, â€˜gamma radiationâ€™, and so on. The point isnâ€™t to explain all of these terms, each of which compresses a whole set of rich insights; itâ€™s that when youâ€™re looking for companies to join, you could do worse than look for a rich internal language or vocabulary that helps you think about things in a more interesting way.

> One of the things that (I think) came from Peter was the idea of not giving people titles. When I was there, everyone had the â€œforward deployed engineerâ€ title, more or less, and apart from that there were five or six Directors and the CEO. Occasionally someone would make up a different title (one guy I know called himself â€œHead of Special Situationsâ€, which I thought was hilarious) but these never really caught on. Itâ€™s straightforward to trace this back to Peterâ€™s Girardian beliefs: if you create titles, people start coveting them, and this ends up creating competitive politics inside the company that undermines internal unity. Better to just give everyone the same title and make them go focus on the goal instead.

> Some people were more influential than others, but the influence was usually based on some impressive accomplishment, and most importantly nobody could tell anyone else what to do. So it didnâ€™t matter if somebody was influential or thought your idea was dumb, you could ignore them and go build something if you thought it was the right thing to do.

> The cost of this was that the company often felt like there was no clear strategy or direction, more like a Petri dish of smart people building little fiefdoms and going off in random directions. But it was incredibly generative.

> This is an uncomfortable stance for many, precisely because youâ€™re not guaranteed to be doing 100% good at all times. Youâ€™re at the mercy of history, in some ways, and youâ€™re betting that (a) more good is being done than bad (b) being in the room is better than not. This was good enough for me. Others preferred to go elsewhere.

## [Palantir Foundry](https://www.palantir.com/platforms/foundry/)

## [â€œContext is that which is scarceâ€](https://marginalrevolution.com/marginalrevolution/2022/02/context-is-that-which-is-scarce-2.html)

> When judging people for leadership positions, or for jobs that require strongly synthetic abilities, you should consider how well they are capable of generating an understanding of context across a broad range of domains, including ex nihilo, so to speak.Â  How to test for understanding of context is itself a topic we could consider in more depth.

## [Lessons from Peter Thiel](https://www.8vc.com/resources/lessons-from-peter-thiel)

> In hiring, value intelligence highly.

> If you are designing something that a customer is going to use or that will represent us in public, itâ€™s not good enough unless itâ€™s flawless and extraordinary.

> Donâ€™t waste time talking about what you plan to think about; instead, work through it immediately.

> So we have to use our judgment to seek out intelligent people who disagree with us â€” or even intelligent people who have simply taken a different approach â€” and be open about what we might learn from them.

> In the abstract, this is because the incentives of the other company will not line up with ours, and even if they do for the moment, they no longer will once the situation changes. In specific, other companies donâ€™t have the same culture of execution that Palantir does, and we donâ€™t have the power to instill that culture in them.

> Instead, itâ€™s often instructive to imagine that you were working from a clean slate and design the feature from scratch.

## [You donâ€™t need a niche, you need a point of view](https://thedankoe.com/letters/you-dont-need-a-niche-you-need-a-point-of-view/)

> When you shift from being a repository of specialized knowledge to being a lens through which people see the world, you become a curator of many ideas across different domains and synthesize them under one body of work. You no longer own a category or topic, you own a perspective that creates a unique constellation of interconnected ideas that canâ€™t be replicated because theyâ€™re filtered through your specific combination of values, experiences, and goals.

## [CS183: Startup - Peter Thiel Class Notes](https://blakemasters.tumblr.com/)

> We tend to think of all computers as more or less identical. Maybe some features are different, but the systems are mostly homogeneous. People, by contrast, are very different from one another. We look at the wide range of human characteristicsâ€”from empathy to cruelty, kindness to sociopathyâ€”and perceive people to be quite diverse. Since people run our legal system, this heterogeneity translates into a wide range of outcomes in disputes. After all, if people are all different, it may matter a great deal who is the judge, jury, or prosecutor in your case. The converse of this super naive intuition is that, since all computers are the same, an automized legal system would be one in which you get the same answer in all sorts of different contexts.

## [å¦‚ä½•ä»æ•Œäººèº«ä¸Šè·ç›Š](https://www.geedea.pro/library/2025/%E5%A6%82%E4%BD%95%E4%BB%8E%E6%95%8C%E4%BA%BA%E8%BA%AB%E4%B8%8A%E8%8E%B7%E7%9B%8A/)

> æ™®é²å¡”å…‹è®¤ä¸ºï¼Œæœ€åº”è¯¥è®­ç»ƒå’Œå®è·µçš„ï¼Œä¸æ˜¯å¦‚ä½•è§„é¿ä¸å¹¸ï¼Œè€Œæ˜¯å¦‚ä½•æŠŠå›°å¢ƒè½¬åŒ–ä¸ºæœºä¼šã€‚äººåº”å½“çæƒœè‡ªå·±æ‹¥æœ‰çš„ï¼Œå¥½å¥½åœ°ä½¿ç”¨å¹¶ä»ä¸­è·å¾—çœŸæ­£çš„å¿«ä¹ï¼Œè¿™æ ·ï¼Œå³ä¾¿æœ‰ä¸€å¤©å¤±å»äº†ï¼Œä¹Ÿèƒ½å¤Ÿæ›´åŠ å¹³é™åœ°é¢å¯¹ã€‚

> å€Ÿè´·äººçš„â€œä¿¡ç”¨â€æ„å‘³ç€ä»–æœ¬æ¥å°±æ‹¥æœ‰è´¢å¯Œï¼Œè€Œæ—¢ç„¶ä»–æœ‰è´¢å¯Œï¼Œä»–åˆä½•å¿…å€Ÿè´·ï¼Ÿå› æ­¤ï¼Œé¿å…å€ºåŠ¡æ‰æ˜¯æœ€å€¼å¾—å¥‰è¡Œçš„ç”Ÿæ´»å‡†åˆ™ã€‚

## [Digital hygiene: Notifications](https://herman.bearblog.dev/notifications/)

> Developing a good relationship to your phone is an intentional process. It doesn't happen by accident. All apps and media, by design, are fighting for your attention. I've heard the term "attention economy" thrown around, and I feel like it's an apt description of the battle for our increasingly fractured attentions.

## [å¯¹è¯å¯Œè¾¾åŸºé‡‘å¼ ç¬‘ç‰§ï¼šå¦‚ä½•å¯»æ‰¾è§£å†³ç¤¾ä¼šé—®é¢˜çš„ â€œåå€è‚¡â€ï¼Ÿ](https://www.xiaoyuzhoufm.com/episode/6892f88646542d8c41bf2169)

> é‚£å…¶å®å¯¹äºä¼ä¸šæ¥è¯´ä¹Ÿæ˜¯è¿™æ ·çš„ï¼Œå°±è¯´å¤§å®¶åœ¨è®¨è®ºè¿™ä¸ªä¼ä¸šèƒ½ä¸èƒ½æœ€ç»ˆå¸®è‚¡ä¸œèµšåˆ°é’±ï¼Œå®ƒå…¶ã€‚å…¶å®æ˜¯æ¥è‡ªäºå®ƒçš„å•†ä¸šåŒ–æ¨¡å¼ï¼Œå®ƒçš„è´§å¸åŒ–æ¨¡å¼ä½ å°±å¿…é¡»è¦å›åˆ°æ ¹å­ä¸Šå»æ€è€ƒæ€ä¹ˆæ ·æ‰èƒ½å¤Ÿè®©è¿™ä¸ªä¼ä¸šæŒç»­åœ°èµšåˆ°é’±ï¼Œé‚£ä¹ˆä¹Ÿå°±æ˜¯ä»–çš„æ¶ˆè´¹è€…ï¼Œä»–çš„å®¢æˆ·å°±è¦æŒç»­åœ°æ„¿æ„ä»˜ä»–é’±ï¼Œå°±å¾€å‰å†æ¨ä¸€æ­¥å‘¢ã€‚å¦‚æœæœ‰ä¸€ä¸ªä¼ä¸šä»–èƒ½å¤Ÿä¸ºç¤¾ä¼šä¸Šçš„ä¸€äº›é‡å¤§çš„é—®é¢˜å»æä¾›ä¸€ç§å¯æŒç»­çš„è§£å†³æ–¹æ¡ˆï¼Œé‚£ä¹ˆåœ¨é•¿æœŸçš„è¿‡ç¨‹ä¸­ï¼Œé‚£ç¤¾ä¼šå°±ä¼šæŒç»­åœ°éœ€è¦è¿™ä¸ªä¼ä¸šçš„æœåŠ¡ã€äº§å“æˆ–è€…æŠ€æœ¯ã€‚æ‰€ä»¥åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç¤¾ä¼šçš„å‚ä¸è€…ï¼Œä¹Ÿå°±æ˜¯ä»–çš„å®¢æˆ·ï¼Œæ— è®ºæ˜¯æ¶ˆè´¹è€…ã€ä¼ä¸šè¿˜æ˜¯æ”¿åºœï¼Œå°±ä¼šæ„¿æ„å‘ä»–æ”¯ä»˜ä¸€ä¸ªå¯¹ä»·ï¼Œè¿™ä¸ªå¯¹ä»·å…¶å®å°±æ˜¯ä»–çš„æ˜¯è´§å¸åŒ–çš„ç»“æœï¼Œæ‰€ä»¥æœ€ç»ˆæˆ‘å»è¯†åˆ«è¿™ä¸ªå¯æŒç»­æˆé•¿çš„è¿™ä¸ªæ–¹æ³•è®ºï¼Œå°±æ€»ç»“ä¸ºæˆ‘å»æ‰¾é‚£äº›èƒ½å¤Ÿä¸ºç¤¾ä¼šé‡è¦é—®é¢˜æä¾›å¯æŒç»­è§£å†³æ–¹æ¡ˆçš„ä¼ä¸šï¼Œé‚£æˆ‘è§‰å¾—ä»–ä»¬åœ¨é•¿æœŸä¸­å°±æœ‰å¤§æ¦‚ç‡èƒ½å¤Ÿä¸ºç¤¾ä¼šæ‰€éœ€è¦ï¼Œç„¶åè·å¾—ç¤¾ä¼šçš„å›é¦ˆï¼ŒåŒæ—¶ä»–ä»¬å°±æœ‰æ›´é«˜çš„æ¦‚ç‡å»åšæœ‰è¾ƒé«˜å›æŠ¥çš„å†æŠ•èµ„ï¼Œç„¶åå½¢æˆåˆ©æ¶¦å±‚é¢çš„ã€ç°é‡‘æµå±‚é¢çš„å¯æŒç»­çš„æˆé•¿ã€‚æ‰€ä»¥è¿™æ ·çš„è¯ä½ å¯ä»¥çœ‹å‡ºæ¥ï¼Œå°±æ˜¯æˆ‘æ‰€å®šä¹‰çš„è¿™ä¸ªå¯æŒç»­çš„æˆé•¿ï¼Œå®ƒçš„è¿™ä¸ªæ¥é¾™å»è„‰ã€‚

> å…¶å®æˆ‘ä»¬å›è¿‡å¤´å»çœ‹ç”µå•†çš„è¯ï¼Œå®ƒå…¶å®è§£å†³çš„å°±æ˜¯ä¸€ä¸ªä¿¡æ¯æµã€ç‰©æµã€èµ„é‡‘æµï¼Œåœ¨ä¸€ä¸ªä¸­å›½å…¨å›½åŒ–çš„ä¸€ä¸ªç»Ÿä¸€å¤§å¸‚åœºè¿™ä¹ˆä¸€ä¸ªæ„å»ºçš„è¿‡ç¨‹ä¸­ï¼Œä» 20 å¹´å‰ä¸­å›½çš„è¿™ä¸ªçº¿ä¸‹é›¶å”®å¯èƒ½æ˜¯éå¸¸å‰²è£‚çš„ï¼Œå®Œå…¨é çº¿ä¸‹æ¸ é“å•†å»é“ºè´§çš„æ¨¡å¼ï¼Œåˆ°ä»Šå¤©åŸºæœ¬ä¸Šåœ¨ä¸­å›½ä»»ä½•ä¸€ä¸ªåœ°æ–¹ç”Ÿäº§çš„äº§å“ï¼Œä½ ä½œä¸ºæ¶ˆè´¹è€…ä½ éƒ½å¯ä»¥å¾ˆè½»æ¾åœ°ä»ç”µå•†ä¸Šã€å¹³å°ä¸Šä¹°åˆ°ã€‚

> æŠ•å…¥ä¼šå¾ˆé«˜ï¼Œä½†æ˜¯æˆ‘ä»¬ä¹Ÿä¼šé—®ä»–è¯´ï¼Œé‚£ä½ æŠ•å…¥ç›¸å¯¹é«˜çš„è¯ï¼Œä½ çš„ ROI ä¼šæ˜¯æ€ä¹ˆæ ·çš„ï¼Ÿæˆ‘è§‰å¾—å½“æ—¶åˆ›å§‹äººæœ‰ä¸€å¥è¯æ‰“åŠ¨æˆ‘ï¼Œè¯´ä»–ä¹Ÿæ— æ³•é¢„æµ‹æˆ–è€…ç»™æˆ‘ä»¬ä¸€ä¸ªæŒ‡å¼•ï¼Œè¯´å®ƒçš„ ROI æ¯”èµ·ç«¯æ¸¸ä¼šé«˜è¿˜æ˜¯ä½ï¼Œä½†æ˜¯ä»–ä»¬åšçš„æ¯ä¸€æ¬¾æ ¸å¿ƒçš„æ¸¸æˆä»–éƒ½ä¼šäº²è‡ªå»ç©ï¼Œä»–ä»¬æ²¡æœ‰é‡‡å–å½“æ—¶å¾ˆç››è¡Œçš„ä½æŠ•å…¥ã€é«˜å‘¨è½¬çš„è¿™ä¸ªæ‰‹æ¸¸å¼€å‘æ¨¡å¼ã€‚é‚£æˆ‘è§‰å¾—è¿™ä¹Ÿæ˜¯ä¸€ç§æ­£ç¡®çš„å·®å¼‚åŒ–ï¼Œæ‰€ä»¥ä¹Ÿå¯¼è‡´äº†åæ¥å…¶å®ä»–ä»¬çš„æ‰‹æ¸¸è½¬å‹æ˜¯éå¸¸æˆåŠŸçš„ï¼Œæˆ‘è§‰å¾—ä»–ä»¬å…¶å®æ˜¯åšæŒäº†ä»–ä»¬å…¬å¸è‡ªå·±çš„å…¬å¸æ–‡åŒ–ï¼Œæ²¡æœ‰åœ¨ä¸€ä¸ªæŠ€æœ¯è½¬å‹çš„è¿‡ç¨‹ä¸­éšæ³¢é€æµï¼Œä½†æ˜¯ä»–ä»¬åœ¨é¢å¯¹æŠ€æœ¯åˆ›æ–°çš„æ—¶å€™åˆæ˜¯éå¸¸ç§¯æå»è¿æ¥çš„ã€‚

> é‚£ä»æŠ•ç ”è§’åº¦æ¥è¯´ï¼Œæƒ…ç»ªä»·å€¼è¿™ä¸ªæŒ‡æ ‡çš„è¯æ˜¯ä¸æ˜¯å¯ä»¥ä½œä¸ºä¸€ä¸ªé‡åŒ–çš„ä¸€ä¸ªä¾æ®å‘¢ï¼Ÿå› ä¸ºè¿™æ–¹é¢å¯èƒ½ä¹Ÿæ˜¯å¤§å®¶ç°åœ¨å¯¹æ–°æ¶ˆè´¹çš„æŠ•ç ”å½“ä¸­é‡åˆ°çš„ä¸€ä¸ªæ¯”è¾ƒå¤§çš„éš¾é¢˜ï¼Œå› ä¸ºå‰å‡ å¹´æˆ‘ä»¬åœ¨è®²ç§‘æŠ€è‚¡çš„æ—¶å€™è¿˜æè¿‡å¸‚æ¢¦ç‡è¿™ä¸ªè¯ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªæ¯”è¾ƒè™šæ— ç¼¥ç¼ˆçš„ä¸€ä¸ªå¸‚åœºé¢„æœŸçš„æ¦‚å¿µã€‚
>
> æˆ‘è§‰å¾—æƒ…ç»ªä»·å€¼è¿™ä¸ªä¸œè¥¿ä¹‹æ‰€ä»¥è®©æŠ•èµ„è€…è¿™ä¹ˆå…´å¥‹ï¼Œè€Œä¸”å®ƒèƒ½å¤Ÿçªç ´æ•´ä¸ªæ¶ˆè´¹ç–²è½¯çš„å®è§‚æ ¼å±€ï¼Œè„±é¢–è€Œå‡ºï¼Œå…¶å®åŒ…å«äº†ä¸€äº›éå¸¸åº•å±‚ã€æ·±å±‚æ¬¡çš„äººæ€§å±‚é¢çš„ä¸œè¥¿ã€‚ä½†æ˜¯è¶Šæ˜¯è¿™æ ·çš„ä¸œè¥¿ï¼Œä½ å…¶å®æ˜¯è¶Šéš¾é‡åŒ–çš„ã€‚

## [è¯»ã€Š1000 ä¸ªé“ç²‰ã€‹](https://manateelazycat.github.io/2025/08/11/1000-fans/)

> æœ‰æ—¶å€™ï¼Œä¸ªäººçš„ç¼ºé™·åè€Œæ˜¯ä¸ªäºº IP çš„è¾¨è¯†åº¦ï¼Œ æ¯”å¦‚éº»åŸå£éŸ³çš„æˆ´è€å¸ˆï¼Œæ­Œæ‰‹å‘¨æ·±ç­‰ã€‚ å› ä¸ºå¤©èµ‹æ¥è‡ªäºä½ çš„ç¼ºé™·ï¼Œä½ æ‰€æœ‰çš„å¼ºé¡¹éƒ½å¯ä»¥è¢«å¤åˆ¶ï¼Œä½†ä½ çš„ç¼ºé™·å´å¾ˆéš¾è¢«æ¨¡ä»¿ã€‚
>
> è¿™ä¹Ÿæ˜¯å¾ˆå¤šç²¾å¿ƒè®¾è®¡å‡ºæ¥çš„è§†é¢‘ï¼Œåè€Œæ²¡æœ‰ä¸€ä¸ªéšæ—¶æ‹çš„è§†é¢‘æ•ˆæœå¥½ï¼Œå› ä¸ºä¸€ä¸ªäººçš„æ„Ÿæƒ…ã€ç¥æ€ã€æƒ…ç»ªæ˜¯æ²¡æ³•ç²¾å¿ƒè®¾è®¡çš„ã€‚

## [å½“æ€è€ƒæŒ‰å­—æ•°æ”¶è´¹](https://anotherdayu.com/2025/7115/)

> æœªæ¥ï¼Œç¨€ç¼ºçš„ä¸æ˜¯çŸ¥è¯†ï¼Œè€Œæ˜¯æ³¨æ„åŠ›ã€éªŒè¯èƒ½åŠ›å’Œæ„ä¹‰å»ºæ„èƒ½åŠ›ã€‚

## [Happiness Research: Get Used to It](https://www.betonit.ai/p/happiness_resea_1html)

> Most of us are familiar with striking examples of people who seem to be adapting well to circumstances that are extremely adverse. We may have seen footage of malnourished children playing happily in garbage dumps or know of severely handicapped people who maintain a cheerful disposition in spite of their disabilitiesâ€¦ This chapter examines both the extent and limits of hedonic adaptation â€” processes that attenuate the long-term emotional or hedonic impact of favorable and unfavorable circumstances.

## [OpenAI's new open-source model is basically Phi-5](https://www.seangoedecke.com/gpt-oss-is-phi-5/)

> As it turns out, it does very well on model benchmarks but disappoints in practice. Searching for the reception to each Phi model shows the same pattern: very impressive benchmarks, lots of enthusiasm, and then actual performance far weaker than the benchmarks would suggest.

> Why would OpenAI train Phi-style models, knowing that theyâ€™ll perform better on benchmarks than in real-world applications? For the same reason that Microsoft probably continued to train Phi-style models: safety.

> Why would OpenAI train Phi-style models, knowing that theyâ€™ll perform better on benchmarks than in real-world applications? For the same reason that Microsoft probably continued to train Phi-style models: safety.
> ...
> Itâ€™s not discussed publically very often, but the main use-case for fine-tuning small language models is for erotic role-play, and thereâ€™s a serious demand. Any small online community for people who run local models is at least 50% perverts.

> For OpenAI, it must have been very compelling to train a Phi-style model for their open-source release. They needed a model that beat the Chinese open-source models on benchmarks, while also not misbehaving in a way that caused yet another scandal for them. Unlike Meta, they donâ€™t need their open-source model to be actually good, because their main business is in their closed-source models.

## [å½’ç±»æ˜¯ç†è§£çš„å‡åŠ¨ä½œï½œ ğŸ¥« é˜…è¯»ç½å¤´ï¼ˆ7 æœˆåˆŠï¼‰](https://quaily.com/shixingcuowu/p/classification-is-a-false-move-reading-can-monthly)

> æˆ‘ä»¬ä¸æ˜¯é å¤´è¡”æˆ–å¿™ç¢Œæ¥å®šä¹‰è‡ªå·±â€”â€”é‚£äº›æ ‡ç­¾ä¸€æ—¦æ¶ˆå¤±ï¼Œä½ ä¼šå‘ç°è‡ªå·±å…¶å®è¿˜åœ¨ï¼Œåªæ˜¯ä¸–ç•Œä¸€æ—¶ä¸å¤ªçŸ¥é“æ€ä¹ˆã€Œçœ‹ã€ä½ ã€‚è¿™ç§æ„Ÿè§‰å¾ˆçœŸå®ï¼Œå°¤å…¶æ˜¯å½“ä½ çªç„¶å¤±ä¸šã€æ¢è§’è‰²ï¼Œæˆ–è€…ç”Ÿæ´»æŒ‰ä¸‹æš‚åœé”®çš„æ—¶å€™
>
> çœŸæ­£å±äºè‡ªå·±çš„ä¸œè¥¿ï¼Œæ¯”å¦‚å¥½å¥‡å¿ƒã€å¹½é»˜æ„Ÿã€çœ‹è§å¾®å°ç¾å¥½çš„èƒ½åŠ›ï¼Œè¿™äº›ä¸ä¼šå› ä¸ºä½ æš‚æ—¶ã€Œæ— æ‰€äº‹äº‹ã€å°±æ¶ˆå¤±ã€‚

## [å´”åº†é¾™\_](https://weibo.com/3762961402/PCUdAqtOx)

> ä¸€ä¸ªå¤æ‚çš„ç°è±¡ï¼ˆæ¯”å¦‚ä¸€ä¸ªäººï¼‰ï¼Œä¾¿æ˜¯å®ƒè‡ªèº«æœ€çŸ­çš„æè¿°ã€‚ä½ æ— æ³•ç”¨ä¸€ä¸ªæ›´ç®€å•çš„å…¬å¼ã€ç†è®ºæˆ–è¯Šæ–­æ ‡ç­¾æ¥å®Œå…¨æ¦‚æ‹¬å®ƒã€‚åœ¨è¿™ä¸ªè§†è§’ä¸‹ï¼Œä»»ä½•ç®€åŒ–éƒ½æ˜¯ä¸€ç§ä¿¡æ¯æŸå¤±ï¼Œä»»ä½•é¢„è®¾éƒ½ä¼šè®©å½¼æ­¤äº§ç”Ÿä¸€ç§è¢«åˆ‡å‰²äº†ä¸»ä½“å®Œæ•´æ€§çš„æŠµæŠ—æ„Ÿã€‚

> æˆ‘ä¹Ÿè®©æˆ‘è”æƒ³åˆ°æ•°å­—æ—¶ä»£çš„ä¸€ç§å›°å±€ï¼Œä¹Ÿå°±æ˜¯ç½‘ç»œä¸Šå‡ºç°çš„è¶Šæ¥è¶Šå¤šã€ä¹Ÿè¶Šæ¥è¶Šç®€åŒ–çš„äººç±»æŒ‡ç§°è¯æ±‡ï¼Œå®ƒå°†æ¯ä¸€ä¸ªç‹¬ç‰¹çš„ç»éªŒä¸ªä½“æ‰“åŒ…å‹ç¼©æˆäº†éå¸¸ç®€æ´çš„æŒ‡ä»¤ï¼Œè¿™æ˜¯ä¸€ç§å¯¹äººç±»ä¸»ä½“æ€§çš„æš´åŠ›åˆ‡å‰²å’Œå…¨ç„¶æ¼ è§†ã€‚

> ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨å¯¹ä¸€ä¸ªäººçš„ç†è§£ä¸Šï¼Œæˆ‘ä»¬èƒ½åšåˆ°çš„æœ€å¤§çš„åŠªåŠ›ï¼Œä»…ä»…æ˜¯å¯¹äºä¸€ä¸ªäººå†…åœ¨ç»éªŒè¿‡ç¨‹çš„æè¿°ï¼Œæˆ‘ä»¬è¶Šæ˜¯èƒ½åšåˆ°è¿™ä¸€ç‚¹ï¼Œå°±è¶Šæ˜¯èƒ½æ¶ˆé™¤äººä¸äººä¹‹é—´çš„éš”é˜‚ä¸æ„¤æ€’ã€‚

## [YAMA: Youâ€™re Always Missing Out (And Thatâ€™s A-Okay)](https://nesslabs.com/yama)

> YAMA recognizes that missing out is a fundamental part of the human condition. Rather than fighting this reality or trying to optimize around it, YAMA suggests simply accepting that weâ€™re finite creatures in an infinite world.

## [I Tried Every Todo App and Ended Up With a .txt File](https://www.al3rez.com/todo-txt-journey)

> What Actually Happened With Each App
> Notion: Built an entire life operating system. Spent three weeks perfecting it. Used it for two days. Now itâ€™s a graveyard of abandoned databases.
>
> Todoist: Great until I realized I was gaming the points system instead of doing actual work. Turns out completing â€œdrink waterâ€ 8 times a day doesnâ€™t make you productive.
>
> Things 3: Beautiful. Expensive. Tricked me into thinking I had my life together. But I kept forgetting to check it.
>
> Trello: Turned my todo list into a board with columns. Realized Iâ€™m not a startup. Iâ€™m just one person trying to remember to buy milk.
>
> OmniFocus: So powerful I needed a manual to use it. Spent more time learning OmniFocus than finishing my actual projects.

## [The Future Isn't Model Agnostic](https://fly.io/blog/the-future-isn-t-model-agnostic/)

> As builders, itâ€™s time we stop hedging our bets and embrace the convergence reality. Every startup pitch deck with â€˜model-agnosticâ€™ as a feature should become a red flag for investors who understand product-market fit. Stop putting â€˜works with any LLMâ€™ in your one-liner. It screams â€˜we donâ€™t know what weâ€™re building.â€™

## [Why Cursor is About to Ditch Vector Search (and You Should Too)](https://www.tigerdata.com/blog/why-cursor-is-about-to-ditch-vector-search-and-you-should-too)

> Turns out, vector databases actually aren't THE solution for everything. There are inherent limitations and downsides to using/implementing/maintaining vector databases that the industry is finally discovering.
>
> Vector search gives you "most similar" stuff, but not necessarily "most relevant" stuff. This is especially painful when it comes to coding, or any use case that requires specificity.

> Vector search should not be applied to text where semantic similarity is irrelevant.

> For coding, similarity != relevance. Similarity is fuzzy; relevance is precise and exact.

## [Kagi Small Web](https://blog.kagi.com/small-web)

> To begin with, while there is no single definition, â€œsmall webâ€ typically refers to the non-commercial part of the web, crafted by individuals to express themselves or share knowledge without seeking any financial gain. This concept often evokes nostalgia for the early, less commercialized days of the web, before the ad-supported business model took over the internet (and we started fighting back!)

## [The small web is beautiful](https://benhoyt.com/writings/the-small-web-is-beautiful/) â­

> However, itâ€™s not just about raw size, but about an â€œethos of smallâ€. Itâ€™s caring about the users of your site: that your pages download fast, are easy to read, have interesting content, and donâ€™t load scads of JavaScript for Google or Facebookâ€™s trackers. Building a website from scratch is not everyoneâ€™s cup of tea, but for those of us who do it, maybe we can promote templates and tools that produce small sites that encourage quality over quantity.

> Itâ€™s been said before, but microservices solve a people problem, not a technical one. But beware of Conwayâ€™s Law: your architecture will mimic your company structure. Or the reverse â€“ youâ€™ll have to hire and reorg so that your company structure matches the architecture that microservices require: lots of engineers on lots of small teams, with each team managing a couple of microservices.

## [é¡¹é£™ Ã— è¿ˆå…‹å°”Â·æ¡‘å¾·å°”ï¼šè¶ŠåŠªåŠ›è¶Šå¹¸è¿æ˜¯ä¸€ç§å‡è±¡](https://mp.weixin.qq.com/s?__biz=MzA3MzYzNjMyMA==&mid=2650225914&idx=1&sn=0aed6e9df71b8bd73e00fc51ac7f3755&chksm=870f9c75b0781563927ad8d5abd3382aa2480ac7a307e85b2bae485f93e0ad9e74a8b527702d&scene=21#wechat_redirect)

> è¿™å°±æ˜¯ä¼˜ç»©ä¸»ä¹‰çš„é»‘æš—é¢ï¼šè¿™ç§æ®‹é…·çš„è¾“èµ¢ä¼¦ç†è®©æˆåŠŸè€…è¿‡äºé£˜é£˜ç„¶ï¼Œäºæ˜¯ä»–ä»¬å¿˜è®°äº†é‚£äº›æˆåŠŸè·¯ä¸Šçš„è¿æ°”å› ç´ å’ŒåŠ©åŠ›â€”â€”å®¶åº­ã€è€å¸ˆã€ç¤¾ä¼šé˜¶å±‚ã€å›½å®¶å’Œæ—¶ä»£ã€‚

## [é¡¹é£™ Ã— è¿ˆå…‹å°”Â·æ¡‘å¾·å°”ï¼šä¸å¤Ÿå¹¸è¿çš„äººï¼Œæ€æ ·è¿‡å¥½è¿™ä¸€ç”Ÿï¼Ÿ](https://mp.weixin.qq.com/s/WoYv_70iuPWgKFFX7uXWLw)

> ä¸çŸ¥é“æˆ‘ä»¬èƒ½å¦åœ¨å¹´è½»äººä¸­æ„å»ºä¸€ç§ç”Ÿæ´»æ„¿æ™¯ï¼Œè®©ä»–ä»¬æ›´åŠ å…³æ³¨å½“åœ°ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä¸€ç›´åœ¨æâ€œé™„è¿‘â€â€”â€”å…³æ³¨ä½ çš„å‘¨å›´ï¼Œäº†è§£é™„è¿‘çš„äººï¼Œä½ çš„çˆ¶æ¯å¦‚ä½•ç”Ÿæ´»ï¼Œè°æ˜¯ä½ çš„é‚»å±…ï¼Œè°åœ¨æ¸…æ‰«ä½ çš„è¡—é“ï¼Œåƒåœ¾æ˜¯å¦‚ä½•è¢«æ”¶é›†çš„ï¼Œç„¶ååœ¨é™„è¿‘ã€åœ¨è§¦æ‰‹å¯åŠçš„ç”Ÿæ´»ä¸­æ‰¾åˆ°æ„ä¹‰ï¼Œè€Œä¸æ˜¯ç™½ç™½åšæ¢¦ã€‚
>
> â€œä½ èƒ½å»åˆ°ä½ æ¢¦æƒ³çš„ä»»ä½•åœ°æ–¹ã€‚â€ä¸æ˜¯çš„ï¼Œä½ è¦çŸ¥é“ï¼Œä½ çš„æ¢¦å¹¶ä¸çœŸæ­£åœ°å±äºä½ è‡ªå·±ï¼Œå®ƒåªæ˜¯éœ¸æƒåœ¨ä½ è„‘æµ·ä¸­çš„æŠ•å½±ã€‚åšç™½æ—¥æ¢¦çš„æ—¶å€™ï¼Œä½ å…¶å®å·²ç»åœ¨æŸç§ç¨‹åº¦ä¸Šæˆä¸ºäº†éœ¸æƒçš„ä¿˜è™ã€‚çœŸæ­£çš„è‡ªæˆ‘æ˜¯åœ¨é™„è¿‘ã€åœ¨ä½ ä¸å‘¨å›´äººçš„å…³ç³»ä¸­æ‰¾åˆ°çš„ã€‚

## [[BUG] Claude says "You're absolutely right!" about everythingÂ #3382](https://github.com/anthropics/claude-code/issues/3382)

> Claude is way too sycophantic, saying "You're absolutely right!" (or correct) on a sizeable fraction of responses.

## [Do things that donâ€™t scale, and then donâ€™t scale](https://derwiki.medium.com/do-things-that-dont-scale-and-then-don-t-scale-9fd2cd7e2156)

> A little over a decade ago, Paul Graham popularized â€œDo things that donâ€™t scale.â€ The idea was: at first, you do the scrappy, personal, labor-intensive stuff just to get tractionâ€¦ and then you figure out how to make it huge.

> But with GPT-assisted coding, I think weâ€™re in an era where you can just stop after the first part. You can do something that doesnâ€™t scaleâ€Šâ€”â€Šand leave it that way. That might actually be the best version of it.
>
> The cost to build is so low now.

> Some things work precisely because theyâ€™re small.

> The version that only works for my mom is the safestâ€Šâ€”â€Šand bestâ€Šâ€”â€Šversion.

> The Pattern
> â€¢ See a need that matters to you.
>
> â€¢ Build the smallest, simplest thing that solves it.
>
> â€¢ Resist the urge to make it bigger.
>
> â€¢ Enjoy it.

> The real luxury of building with todayâ€™s tools isnâ€™t speed, or cost, or even the magic of AIâ€Šâ€”â€Šitâ€™s the freedom to stop.

## [çŸ¥è¶³å¸¸ä¹-æ°´æ˜ŸæŠ•èµ„ç†è´¢çš„åŸºæœ¬æ„å¿µ](http://mercurychong.blogspot.com/2025/08/blog-post.html)

> æ™‚é–“å½·å½¿åªæœ‰åœ¨æˆ‘å€‘èº«ä¸Šéœæ­¢ï¼Œåœ¨å°å­©èˆ‡é•·è¼©èº«ä¸Šå»æ˜¯åŠ é€Ÿæ²–åˆ·è‘—ã€‚

## [Do Things that Don't Scale](https://paulgraham.com/ds.html)

## [My favourite German wordÂ¶](https://vurt.org/articles/my-favourite-german-word/)

> My favourite word in the German language is Gegenstand, for object or thing.
>
> Gegenstand, â€œstand-againstâ€. An object is something that stands against you. Itâ€™s not you. Itâ€™s outside you. It has its own rules. It doesnâ€™t conform to your desires. You run up against it, and it resists.
>
> Objects arenâ€™t just inert stuff â€“ they do something. Even better, Gegenstand shows how objects help define us. I know what I am, what the limits of myself are, because I am able to come up against resistant objects. Thatâ€™s how I know and have a sense of my own body, its extension in space, where it ends and where the world begins.
>
> I am able to have a self in the first place only because the world of objects is there to stand against me.

## [Dicing an Onion the Mathematically Optimal Way](https://pudding.cool/2025/08/onions/)

## [GPT-5: The Reverse DeepSeekÂ Moment](https://thezvi.wordpress.com/2025/08/18/gpt-5-the-reverse-deepseek-moment/)

> The problem is that the release was so botched that OpenAI is now experiencing a Reverse DeepSeek Moment â€“ all the forces that caused us to overreact to DeepSeekâ€™s r1 are now working against OpenAI in reverse.
>
> This threatens to give Washington DC and its key decision makers a very false impression of a lack of AI progress, especially progress towards AGI, that could lead to some very poor decisions, and it could do the same for corporations and individuals.

> We had the DeepSeek Moment because of a confluence of factors misled people:
>
> The â€˜six million dollar modelâ€™ narrative gave a false impression on cost.
> They offered a good clean app with visible chain of thought, it went viral.
> The new style caused an overestimate of model quality.
> Timing was impeccable, both in order of model releases and within the tech tree.
> Safety testing and other steps were skipped, leaving various flaws, and this was a pure fast follow, but in our haste no one took any of that into account.
> A false impression of â€˜momentumâ€™ and stories about Chinese momentum.
> The â€˜always insist open models will winâ€™ crowd amplified the vibes.
> The stock market was highly lacking in situational awareness, suddenly realizing various known facts and also misunderstanding many important factors.

## [37 å²é€€ä¼‘ä¸€å‘¨å¹´ï¼šç»éªŒä¸å¿ƒå¾—åˆ†äº«](https://yfzz.net/?p=89)

> è®¡åˆ’çš„æ ¸å¿ƒæ˜¯åšå¥½ä¸‰ä»¶äº‹ï¼šè´¢åŠ¡ã€å¿ƒç†ã€å®¶äººã€‚
>
> å…¶ä¸­è´¢åŠ¡ä¸Šçš„å‡†å¤‡æ˜¯æœ€å®¹æ˜“é‡åŒ–å’Œæ‰§è¡Œçš„ï¼Œä¹Ÿå¾€å¾€æ˜¯ç¬¬ä¸€æ­¥ï¼›å¿ƒç†å»ºè®¾åˆ™æ›´å¤æ‚ï¼Œå®ƒè¦æ±‚ä½ ç›´é¢å†…å¿ƒã€ä¸¥å®ˆçºªå¾‹ã€ç ´é™¤éšœç¢ï¼Œæ˜¯ç¬¬äºŒæ­¥ï¼›è‡³äºå®¶äººçš„æ”¯æŒï¼Œæ¯ä¸ªå®¶åº­çš„æƒ…å†µéƒ½ä¸åŒï¼Œå‡ ä¹æ— æ³•å€Ÿé‰´ä»–äººç»éªŒï¼Œåªèƒ½é è‡ªå·±å»æ‘¸ç´¢ä¸æ²Ÿé€šã€‚

> å¯¹äºæœ¬é‡‘çš„ç§¯ç´¯ï¼Œå¤§å¤šæ•°äººéƒ½æ˜¯é€šè¿‡è‡ªå·±çš„â€œäººåŠ›èµ„æœ¬â€æ¥æ¢â€œé‡‘èèµ„æœ¬â€ï¼Œé€šä¿—çš„è®²å°±æ˜¯ä¸Šç­èµšé’±ã€‚è€ŒäººåŠ›èµ„æœ¬æœ€å€¼é’±çš„æ—¶å€™ï¼Œæ˜¯åœ¨ 40 å²ä¹‹å‰ã€‚åœ¨æ–°å…´ä¸”éœ€è¦ç»ˆèº«å­¦ä¹ çš„è¡Œä¸šï¼Œè¿™ä¸ªå¹´é¾„ç•Œé™å¾€å¾€è¿˜ä¼šæå‰ï¼Œå¯èƒ½åˆ° 35 å²å·¦å³ã€‚

> å¯ä¸€æ—¦ä½ å¼€å§‹ FIREï¼Œç¦»å¼€å·¥ä½œå²—ä½ï¼Œå½“é—¨ç¦å¤±æ•ˆã€å·¥ä½è¢«æ”¶å›ã€ä¼ä¸šå¾®ä¿¡æ³¨é”€ï¼Œå¤–ç•Œå¯¹ä½ çš„æ€åº¦ä¹Ÿä¼šéšä¹‹æ”¹å˜ã€‚ä½ ä¸å†è¢«æ‹œæ‰˜å¸®å¿™ï¼Œèšä¼šä¸­ä¹Ÿä¸å†æ˜¯ç„¦ç‚¹ï¼Œç”šè‡³æœ¬æ¥ç»å¸¸è”ç³»çš„äººä¹Ÿæ¸æ¸æ²‰é»˜ï¼Œå¾ˆå¤šäººæ­¤æ—¶ä¼šç–‘æƒ‘ï¼šæˆ‘åˆ°åº•æ˜¯è°ï¼Ÿæˆ‘è¿˜ç®—ä»€ä¹ˆï¼Ÿ
>
> ä¸€ä¸ªäººçš„ä»·å€¼ä¸èƒ½åªè¢«å·¥ä½œå®šä¹‰ï¼Œå·¥ä½œä¹‹å¤–çš„ä½ ï¼Œä¹Ÿéœ€è¦æœ‰è‡ªæˆ‘è®¤åŒå’Œå¿ƒç†è°ƒèŠ‚çš„èƒ½åŠ›ã€‚å¦åˆ™ï¼Œä¸€æ—¦èº«ä»½æ ‡ç­¾è¢«å‰¥ç¦»ï¼Œå†…å¿ƒå¾ˆå®¹æ˜“é™·å…¥å¤±è½ä¸è¿·èŒ«ã€‚

> æ¯ä¸ªäººæƒ³è¦çš„é€€ä¼‘ç”Ÿæ´»éƒ½ä¸ç›¸åŒï¼Œä½†å¤§æ¦‚ç‡æ˜¯æƒ³æ‘†è„±ä»–äººçš„è¦æ±‚ã€æœŸæœ›ï¼Œå›å½’è‡ªå·±çš„çƒ­çˆ±ï¼š
>
> ç¨‹åºå‘˜ç»ˆäºèƒ½å†™â€œæ— ç”¨ä½†æœ‰è¶£â€çš„ä»£ç 
> æ¸¸æˆäººå°è¯•å¼€å‘ç‹¬ç«‹æ¸¸æˆ
> æ‰‹å·¥çˆ±å¥½è€…ä¸“æ³¨å°ä¼—ä½†æ»¡è¶³è‡ªæˆ‘çš„åˆ›ä½œ
> ç”šè‡³ç†ç›´æ°”å£®çš„â€œè™šåº¦å…‰é˜´â€

## [Your Review: Dating Men In The Bay Area](https://www.astralcodexten.com/p/your-review-dating-men-in-the-bay)

> Sometimes Iâ€™m convinced thereâ€™s a note taped to my back that says, â€œPLEASE SPILL YOUR SOUL UPON THIS WOMAN.â€ I am not a therapist, nor in any way certified to deal with emotional distress, yet my presence seems to cause people to regurgitate their traumas.
>
> This quirk of mine becomes especially obvious when dating. Many of my dates turn into pseudo-therapy sessions, with men sharing emotional traumas theyâ€™ve kept bottled up for years. One moment Iâ€™m learning about his cat named Daisy, and then half a latte later, Iâ€™m hearing a detailed account of his third suicide attempt, complete with a critique of the food in the psychiatric ward.

## [Yocar-å†¯éª¥](https://weibo.com/6603744955/5201567986483550)

> ã€Šé»‘ç¥è¯ï¼šæ‚Ÿç©ºã€‹å‘å”®åæœ‰ç›¸å½“é•¿ä¸€æ®µæ—¶é—´ï¼Œæˆ‘è¿‡å¾—äº‘é‡Œé›¾é‡Œã€‚
> ä¸€ä¸ªå¿ƒå¿ƒå¿µè¿‘äºŒåå¹´çš„äº‹æƒ…ï¼Œç»ˆäºç­‰åˆ°ä¸€ä¸ªç»“æœã€‚è€Œè¿™ä¸ªç»“æœï¼Œè¶…å‡ºæœ€åˆçš„é¢„æœŸå¤ªå¤šã€‚
> æŒ‰ç†è¯´ï¼Œåº”è¯¥æ»¡åœ°æ‰“æ»šï¼Œåº”è¯¥å¤©å¤©è½»å“¼ã€‚
> é—æ†¾çš„æ˜¯äººç±»åº•å±‚çš„é¢„è®¾ä¸æ˜¯è¿™æ ·ï¼Œå¼ºçƒˆçš„æ­£é¢æƒ…ç»ªæŒç»­æ—¶é—´å¥½åƒéƒ½ç‰¹åˆ«çŸ­ï¼Œå¿«ä¹æ€»æ˜¯ä¸€çœ¨çœ¼å°±è¿‡å»ã€‚
> é‚£æ®µæ—¶é—´æˆ‘è„‘å­é‡ŒçœŸæ­£æŒ¥ä¹‹ä¸å»çš„ï¼Œä¸»è¦æ˜¯è¿·èŒ«ã€è™šæ— ä¸æƒ¶æï¼ˆæˆ‘çŸ¥é“è¿™ä¹ˆè¯´å¾ˆçŸ«æƒ…ï¼Œåˆ«å¼€æªï¼‰ã€‚å¯æ— è®ºæˆ‘æ€ä¹ˆä¸ºè‡ªå·±â€œå¿«ä¹ä¸èµ·æ¥â€æ„Ÿåˆ°ç¾æ„§ï¼Œè¿™äº›æƒ…ç»ªä¾ç„¶ä¸å—æ§åˆ¶åœ°è¢­æ¥ï¼Œè€Œä¸”æ±¹æ¶Œæ¾æ¹ƒâ€”â€”å°¤å…¶æ˜¯è¢«æ·¹æ²¡åœ¨â€œDLC åˆ°åº•åšæ²¡åš DLC éƒ½æœ‰è°å•¥æ—¶å€™å‘ DLCâ€çš„æ—¶å€™ã€‚

> ã€Šå²©ç”°å…ˆç”Ÿã€‹ä¸€ä¹¦ä¸­ï¼Œä»»å¤©å ‚çš„è€ç¤¾é•¿è¯´ï¼šâ€œåœ¨æ—¢æœ‰çš„å»¶é•¿çº¿ä¸Šï¼Œæ˜¯æ²¡æœ‰æœªæ¥çš„ã€‚â€

## [çŸ­è§†é¢‘é‡Œçš„ä¸­è€å¹´äººï¼Œé¥­æ¡Œä¸Šçš„å¯¼å¸ˆ](https://blog.bxaw.name/archives/Addicted-to-Short-Videos-Wise-Men-at-the-Dinner-Table.html) â­

## [How AI researchers accidentally discovered that everything they thought about learning was wrong](https://nearlyright.com/how-ai-researchers-accidentally-discovered-that-everything-they-thought-about-learning-was-wrong/) â­

> Five years ago, suggesting that AI researchers train neural networks with trillions of parameters would have earned you pitying looks. It violated the most fundamental rule in machine learning: make your model too large, and it becomes a glorified photocopier, memorising training data whilst learning nothing useful.
>
> This wasn't mere conventionâ€”it was mathematical law, backed by three centuries of statistical theory. Every textbook showed the same inexorable curve: small models underfit, optimal models generalise, large models catastrophically overfit. End of story.

> For over 300 years1, one principle governed every learning system: the bias-variance tradeoff. The mathematics was elegant, the logic unassailable. Build a model too simple, and it misses crucial patterns. Build it too complex, and it memorises noise instead of signals.

<https://www.pnas.org/doi/10.1073/pnas.1903070116>

> The models didn't collapse. After an initial stumble where they appeared to memorise their training data, something extraordinary occurred. Performance began improving again. Dramatically.
>
> The phenomenon earned the name "double descent"â€”first the expected rise in error as models overfit, then an unexpected second descent as they somehow transcended overfitting entirely. Mikhail Belkin and his colleagues, who documented this discovery, noted it "contradicts conventional wisdom derived from bias-variance analysis."

> Hidden within every large network, they found "winning tickets"â€”tiny subnetworks that could match the full network's performance. They could strip away 96% of parameters without losing accuracy. The vast majority of every successful network was essentially dead weight.
>
> But here lay the crucial insight: these winning subnetworks only succeeded with their original random starting weights. Change the initial values, and the same sparse architecture failed completely.

> The lottery ticket hypothesis crystallised: large networks succeed not by learning complex solutions, but by providing more opportunities to find simple ones.
> ...
> Training becomes a massive lottery draw, with the best-initialised small network emerging victorious whilst billions of others fade away.

> this reframes intelligence itself.
> ...
> Intelligence isn't about memorising informationâ€”it's about finding elegant patterns that explain complex phenomena. Scale provides the computational space needed for this search, not storage for complicated solutions.

> For AI development, this understanding suggests both promise and limits. Scaling works because larger models provide more lottery tickets, more chances to find optimal solutions. But this mechanism implies natural bounds. As networks become more successful at finding minimal solutions, additional scale yields diminishing returns.
>
> This aligns with expert concerns about current approaches' limits. Yann LeCun argues that fundamental architectural constraints may prevent language models from achieving true understanding regardless of scale.

> The accidental discovery that revolutionised AI offers a profound lesson: the universe often holds elegant surprises for those bold enough to test conventional wisdom's boundaries.

## [OnlyFans ä¸ºä»€ä¹ˆè¿™ä¹ˆç«](https://coindollarpay.com/why-onlyfans-is-so-popular/) â­

> æ‰€ä»¥æ‰æœ‰äººè¯´ï¼Œç”± Assï¼ˆå±è‚¡ï¼‰é©±åŠ¨çš„ç»æµåŠ¨åŠ›ï¼Œè¿œè¿œè¶…è¿‡äº†ç”± AIï¼ˆäººå·¥æ™ºèƒ½ï¼‰ï¼ŒOnlyFans å•å¹³å°çš„æ”¶å…¥å°±æ¯”æ‰€æœ‰ AI æ–°å…´å…¬å¸åŠ èµ·æ¥è¿˜å¤šï¼Œæ˜¯çš„ï¼ŒæŠŠä½ æƒ³å¾—èµ·åå­—çš„ AI å…¬å¸ï¼ŒOpenAIã€Midjourneyã€Runway ç­‰ç­‰å…¨éƒ¨åŠ èµ·æ¥ï¼Œéƒ½æ¯”ä¸ä¸Š OnlyFans èƒ½èµšé’±ã€‚
>
> AI è´Ÿè´£æ”¹å˜æœªæ¥ï¼ŒAss è´Ÿè´£æ»¡è¶³å½“ä¸‹ï¼Œçœ‹æ¥å¤§å®¶éƒ½è¿˜æ˜¯ä¸æ€ä¹ˆå–œæ¬¢å»¶è¿Ÿæ»¡è¶³çš„ â‹¯â‹¯

## [Less is more](https://yinji.org/5366.html) â­

## [æ”¹å˜ä¸–ç•Œä¸ä¸è¢«ä¸–ç•Œæ”¹å˜](https://www.savouer.com/9433.html)

> ä¹°è‚¡ç¥¨å°±åº”è¯¥é€‰ä¸ä¼šè¢«ä¸–ç•Œæ”¹å˜çš„å…¬å¸ï¼Œå’Œèƒ½æ”¹å˜ä¸–ç•Œçš„å…¬å¸

> ä¸ä¼šè¢«ä¸–ç•Œæ”¹å˜çš„å…¬å¸ï¼Œå…¶ä¸šåŠ¡å¤©ç„¶å…·æœ‰ä¸å—ç§‘æŠ€è¿›æ­¥å½±å“çš„å®šåŠ›ï¼Œå› æ­¤ä»–ä»¬å¤©ç„¶åº”è¯¥ä¸å…·å¤‡â€œå…ˆè¿›â€å±æ€§ã€‚å¦‚æœä»»ä½•ä¸œè¥¿æ˜¯é æŠ€æœ¯ç«äº‰é¢†å…ˆè€Œå æœ‰ä¼˜åŠ¿çš„ï¼Œé‚£ä¹ˆå®ƒä¾¿ä¸æ˜¯ä½†æ–Œæ‰€è¯´çš„ä¸ä¼šè¢«ä¸–ç•Œæ”¹å˜çš„å…¬å¸ï¼Œå› ä¸ºç§‘æŠ€çš„ä¸œè¥¿å¤§å¤šæ•°éƒ½æ˜¯çŸ­å‘½çš„ã€‚

> æˆ‘ä»¬åŸæ¥åœ¨ A è‚¡ï¼Œæ‰€ä»¥åŠªåŠ›å¯»æ‰¾ä¸ä¼šè¢«ä¸–ç•Œæ”¹å˜çš„å…¬å¸ï¼›ç°åœ¨æˆ‘ä»¬è¸è¶³å›½é™…å¸‚åœºï¼Œæ‰€ä»¥æˆ‘ä»¬å¯»æ‰¾èƒ½å¤Ÿæ”¹å˜ä¸–ç•Œçš„å…¬å¸

## [How does Palantir help organizations comply with data protection and security requirements?](https://blog.palantir.com/about-palantir-ddddb78aec29)

> We refer to the systematic mapping of data, logic, and action to meaningful semantic concepts as an â€œontology.â€ Organizations benefit from building and using an Ontology to organize and leverage their data, enabling connectivity at scale to view local decisions in a more global context, interpretability for more robust and effective analysis, economies of scale with the ability to build entire applications and use cases in the existing Ontology, decision capture through write back actions made in-platform to original source systems, and operational AI/ML directly in-platform.

## [112. å’Œå¹¿å¯†èŠå¤§æ¨¡å‹å­£æŠ¥ï¼šåˆ†åŒ–ä¸æ”¶æ•›ã€å…¨å®¶æ¡¶ä¸å‚ç›´æ•´åˆã€L4 ä½“éªŒä¸æŒ–çŸ¿çª—å£](https://www.xiaoyuzhoufm.com/episode/68a370be293471fed447c691)

> çŠ¹å¤ªäººçš„é‡‘èï¼Œåäººçš„ AGI

> å‰ä¸‰å®¶å°±æ˜¯ OpenAIã€Geminiã€ Anthropic è¿™ä¸‰ä¸ª AI labï¼Œæˆ‘è§‰å¾—æ˜¯å«æ™ºèƒ½ä¸ºå…ˆçš„ä¸€ä¸ªæ–‡åŒ–ã€‚åˆ°åº•æ˜¯æ™ºèƒ½ä¸ºå…ˆè¿˜æ˜¯äº§å“ä¸ºå…ˆï¼Ÿå…¶å®å¯¹æ•´ä¸ªå›¢é˜Ÿçš„é…ç½®å’Œæ€è€ƒé—®é¢˜çš„æ–¹å¼å…¶å®å½±å“è¿˜æ˜¯å¾ˆå¤§çš„ã€‚æˆ‘çŒœ Mira å¯èƒ½æ˜¯ä»¥äº§å“ä¸ºå…ˆçš„ï¼Œå› ä¸º Mira å¯èƒ½è§‰å¾—ç°æœ‰çš„æ™ºèƒ½æŠ€æœ¯å·²ç»èƒ½åšå‡ºå¾ˆå¥½çš„äº§å“ï¼Œæ‰€ä»¥æ¯”å¦‚è¯´æ¢ç´¢ä¸‹ä¸€ä»£çš„äº§å“å’Œä¸‹ä¸€ä»£çš„äº¤äº’ï¼Œæˆ‘è§‰å¾—è¿™ä¸ªä¸ºå…ˆä¹Ÿæ˜¯è›®æœ‰æ„æ€çš„å—¯ã€‚å—¯ï¼Œç¬¬ä¸‰å°±æ˜¯æˆ‘è§‰å¾— Mirra æ˜¯å…¨çƒèŒƒå›´å†…æœ‰å¯èƒ½é€‚åˆåšè‹¹æœå…¬å¸ CEO çš„ï¼Œå°±æ˜¯äº§å“ä¸ºå…ˆçš„ç†å¿µä¹Ÿæ˜¯ match è‹¹æœçš„ï¼Œæˆ‘è§‰å¾—æˆ‘ä»¬å¯ä»¥è§‚å¯Ÿæœªæ¥ä¸€ä¸¤å¹´è‹¹æœè‘£äº‹ä¼šæ˜¯å¦ä¼šé‚€è¯· Mira è¿‡å»ï¼Œæˆ‘è§‰å¾—æ˜¯å¯ä»¥æœŸå¾…ä¸€ä¸‹çš„ï¼Œå°±æ˜¯å¦‚æœè¿™æ˜¯ä»€ä¹ˆè„‘æ´è¿™ä¸ªçŒœæµ‹ï¼Œç„¶åå¦‚æœè‹¹æœæ²¡æœ‰ä¸€ä¸ªçœŸæ­£æ‡‚ AI çš„å›¢é˜Ÿï¼Œé‚£ä¸‹ä¸€ä»£æ‰‹æœºå¦‚ä½•è§„åˆ’éƒ½å¾ˆéš¾å‘¢ï¼Ÿå› ä¸ºä¸‹ä¸€ä»£æ‰‹æœºçš„æ ¸å¿ƒåˆ°åº•æ˜¯ä»€ä¹ˆï¼Ÿæ˜¯æ›´ä¸»åŠ¨æ–°çš„äº¤äº’ï¼Œè¿˜æ˜¯ 24 ä¸ªå°æ—¶çš„ always on çš„èƒ½åŠ›ï¼Ÿä¸ç„¶æˆ‘è§‰å¾—è‹¹æœç®¡ç†å±‚å¯èƒ½æ— æ³•è§„åˆ’ä¸‹ä¸€ä»£æ‰‹æœºçš„ã€‚

> å¦‚æœä»Šå¤©æœ‰ 100 å—é’±ä¹°è‚¡ç¥¨ï¼Œä½ ä¼šä¹°è°å®¶çš„è‚¡ç¥¨å•Šï¼Ÿâ€‹
>
> æˆ‘ä¼šï¼Œå¦‚æœæ˜¯ä»Šå¤©è¿™ä¸ªæ—¶é—´åˆ‡ç‰‡ä¸‹çš„å›ç­”ï¼Œ 40 å—é’±æˆ‘ä¼šæ”¾åˆ° open iï¼Œå—¯ï¼Œ 40 å—é’±ä¹°å­—èŠ‚çš„è‚¡ç¥¨ï¼Œ 10 å—é’±ç»™ Anthropicï¼Œ 10 å—é’±ç»™ Googleã€‚

> å°±æ˜¯ä»Šå¹´ 25 å¹´æ¥äº†ä¹‹åï¼Œæˆ‘æ„Ÿè§‰ ChatGPT ç»å†äº†ä¸€ä¸ªå“ç‰Œçš„å¤§ä¼—åŒ–çš„ä¸‹æ²‰ã€‚å°±æ˜¯å°¤å…¶æ˜¯ä»–çš„å¿ƒæ™ºå’Œå“ç‰Œçš„å£å’ä»Šå¹´æ˜¯åœ¨å¤§å¤§å˜å¼ºçš„ï¼Œå¢é•¿è¿˜åœ¨åŠ é€Ÿï¼Œä»–çš„é™¡å³­ç¨‹åº¦æ¯”å…¶ä»–äººéƒ½è¦é™¡å³­çš„ï¼Œå°±æ˜¯å®ƒæœ‰å¯èƒ½æ˜¯è¿ˆè¿‡äº†æŸä¸ªå¤§ä¼—ç”¨æˆ·æ¸—é€çš„é—¨æ§›ã€‚å°±ä»Šå¤©ä½ é—®å¾ˆå¤šèº«è¾¹çš„æ–°çš„ AI çš„ç”¨æˆ·ï¼Œå…¶å®å¾ˆå¤§æ¯”ä¾‹çš„ç”¨æˆ·ä¼šæŠŠ ChatGPT å½“ä¸€ä¸ªé¦–é€‰çš„ AI å·¥å…·

> å°±æ˜¯å¦‚æœä»Šå¤©æˆ‘æ˜¯ä¸€ä¸ª a i åˆ›ä¸šå…¬å¸çš„ CEOï¼Œæˆ‘æ€ä¹ˆå»é¢å¯¹å¤´ä¸Šçš„è¿™å‡ ä¸ªæ¨¡å‹å…¬å¸çš„ç«äº‰ï¼Ÿæˆ‘æ‰‹ä¸Šæ˜¯æ²¡æœ‰ç¡¬ç‰Œçš„ï¼Œåªèƒ½ç¡¬ç€å¤´çš®å¾€å‰èµ°çš„ã€‚

> ä¸Šä¸€ä»£çš„äº§å“ç»ç†å¾ˆå¤šéƒ½æ˜¯ç å†œå‡ºèº«ï¼Œå°±ç å†œå‡ºèº«çš„äººï¼Œå…¶å®ä»–ä»¬èƒ½çŸ¥é“å“ªäº›åŠŸèƒ½æ˜¯å¯ä»¥å®ç°çš„ï¼Ÿä½†æ‰€ä»¥ä½ çœ‹ï¼Œæ‰€ä»¥æˆ‘ä»¬å°±å€¾å‘äºè¯´è¿™ä¸€ä»£çš„äº§å“ç»ç†å¤§æ¦‚ç‡å¯èƒ½æ˜¯ç®—æ³•æˆ–è€…æ¨¡å‹å‡ºèº«ï¼Œä»–åˆæ¯”è¾ƒï¼Œä»–åˆæœ‰æ¯”è¾ƒå¥½çš„äº§å“æˆ–è€…ä¸šåŠ¡çš„ senseã€‚å°±ä¸ç„¶çš„è¯ä½ å°±æ²¡æ³•åˆ©ç”¨å¥½å…³é”®çš„æ¨¡å‹çš„çº¢åˆ©ï¼Œé‚£ä¹Ÿæ— æ³•åˆ¤æ–­å¥½è¿™ä¸ªæœªæ¥ 6 ~ 12 ä¸ªæœˆæ¨¡å‹çš„å˜åŒ–ã€‚å—¯ï¼Œæ‰€ä»¥è‚¯å®šå€¾å‘äºè¯´ä»æ¨¡å‹ï¼Œæ¯”è¾ƒæ‡‚æ¨¡å‹çš„è¿™å¸®äººé‡Œé¢æ‰¾ã€‚

> å°±æ˜¯ä½ åœ¨ç¾å›½å¾…ä¹…äº†ï¼Œå°¤å…¶åœ¨åŠ å·å°±ä¼šæœ‰ä¸€ä¸ªçªå‡ºæ„Ÿè§‰ï¼Œå°±æ˜¯ç¾å›½ç°åœ¨æœ€æ ¸å¿ƒçš„æ˜¯ä¸¤ä»¶äº‹ï¼Œä¸€ä¸ªæ˜¯å«é‡‘èçš„é“¸å¸æƒï¼Œå—¯ï¼Œä¸€ä¸ªæ˜¯ç¡…è°·çš„ç§‘æŠ€é¢†å…ˆï¼Œå°±é™¤äº†è¿™ä¸¤ä¸ªä¸œè¥¿ï¼Œå¯èƒ½ç¾å›½çš„å…¶ä»–ä¸œè¥¿éƒ½åœ¨è¢«ä¸­å›½çš„äº§ä¸šåŒ–èš•é£Ÿï¼Œè€Œä¸”èš•é£Ÿå¾—å¾ˆå‰å®³ï¼Œ

> æ‰€ä»¥è¿™å°±æ˜¯éå…±è¯†ï¼Œå°±æ˜¯è¯­è¨€æ˜¯ä¸€ä¸ªå¾ˆç‰¹åˆ«çš„ä¸œè¥¿ï¼Œå—¯ï¼Œè¯­è¨€å’Œ code å’Œ pattern è¿™äº›ä¸œè¥¿æ˜¯å¾ˆä¸ä¸€æ ·çš„ï¼Œå—¯ï¼Œæ‰€ä»¥æˆ‘è§‰å¾—è¿™æœ‰å¯èƒ½æ˜¯éå…±è¯†ã€‚å—¯ï¼Œæœºå™¨äººå¯èƒ½ä¸ä¼šé‚£ä¹ˆå¿«çš„ï¼Œå¯èƒ½è¿˜éœ€è¦è¿ˆè¿‡å¥½å‡ ä¸ª GP4 çº§åˆ«çš„æŠ€æœ¯æˆç†Ÿçš„ã€‚

## [ğŸ’»ğŸ•µï¸ THE NVIDIA AI GPU BLACK MARKET ğŸ’¸ | Smuggling, Corruption & Global Scandal ğŸŒğŸ”¥](https://rumble.com/v6xro9o--the-nvidia-ai-gpu-black-market-smuggling-corruption-and-global-scandal-.html)

## [Conversation](https://x.com/vasumanmoza/status/1926487201463832863)

> Claude 4 just refactored my entire codebase in one call.
>
> 25 tool invocations. 3,000+ new lines. 12 brand new files.
>
> It modularized everything. Broke up monoliths. Cleaned up spaghetti.
>
> None of it worked.
> But boy was it beautiful.

## [The leverage paradox](https://www.indiehackers.com/post/lifestyle/the-leverage-paradox-ksRiX6y6W7NzfBE57dzt)

> When my family and I were driving through France a few years ago, we were enchanted by the hundreds of storybook cows grazing on picturesque pastures right next to the highway.
>
> Then, within twenty minutes, we started ignoring the cows. â€¦ Cows, after youâ€™ve seen them for a while, are boring. They may be perfect cows, attractive cows, cows with great personalities, cows lit by beautiful light, but theyâ€™re still boring.
>
> A Purple Cow, though. Now that would be interesting.

## [ä¸è„±è£¤å­å¦‚ä½•è¯æ˜è‡ªå·±å±Œæ›´å¤§ï¼Ÿ](https://www.geedea.pro/posts/%E4%B8%8D%E8%84%B1%E8%A3%A4%E5%AD%90%E5%A6%82%E4%BD%95%E8%AF%81%E6%98%8E%E8%87%AA%E5%B7%B1%E5%B1%8C%E6%9B%B4%E5%A4%A7/)

> æ¯”å±Œå¤§è¿™ä¸ªè¯´æ³•å…´è®¸æœ‰äº›æ€§åˆ«æ­§è§†çš„æ„å‘³ï¼Œä½†å¥‡æ€ªçš„æ˜¯ï¼Œè¿™ç§è¡Œä¸ºæ¨¡å¼çš„ç¡®åœ¨ç”·æ€§èº«ä¸Šæ›´å¸¸è§ï¼Œå®ƒçš„å¦ä¸€ä¸ªåå­—å«åšã€Œæ¯”è°å°¿å¾—è¿œã€ã€‚é›„æ€§ä¼¼ä¹æœ‰ä¸€ç§å¤©ç„¶çš„èƒœè´Ÿæ¬²ï¼Œè¿™ç§èƒœè´Ÿæ¬²ä¸åªä½“ç°åœ¨æ€§èƒ½åŠ›å’Œæ’ä¾¿çš„èƒ½åŠ›ä¸Šï¼Œè¿˜è¢«æŠ•å°„åˆ°äº†å„ä¸ªæ–¹é¢ã€‚

## [æœ€äº†ä¸èµ·çš„ä¸ªäººèƒ½åŠ›](https://www.hecaitou.com/2025/08/The-most-amazing-personal-ability.html)

> ä¸€ä¸ªäººçœŸæ­£å†³å®šè¦å»åšä»€ä¹ˆçš„æ—¶å€™ï¼Œé‚£å°±å»åšäº†ã€‚ä¸€ä¸ªäººå†³å®šä¸è¦å»åšä»€ä¹ˆï¼Œåˆæ‰¿è®¤è‡ªå·±å…¶å®åº”è¯¥å»åšçš„æ—¶å€™ï¼Œå“‡ï¼Œé‚£ä¸ªè¯å°±å¤šäº†ï¼Œä¸Šè‡³å¤©æ–‡ä¸‹è‡³åœ°ç†ä¸­é—´åŠ ä¸ŠæƒåŠ›ç»“æ„åˆ†æï¼Œå¹³å¸¸ä¸‰é”¤æ‰“ä¸å‡ºä¸ªé—·å±çš„äººï¼Œè¿™æ—¶å€™éšä¾¿éƒ½èƒ½ç»™ä½ å†™å‡ºå‡ ç™¾å­—è®ºè¯ä¸¥è°¨ï¼Œè¯æ®å……åˆ†çš„å°è®ºæ–‡æ¥ã€‚å°±ä¸ºäº†è¯´æ˜ä¸€ä»¶äº‹ï¼šä¸å¯è¡Œã€‚

> æ‰€ä»¥è¿™å°±æ˜¯æˆ‘å†…å¿ƒçš„çœŸå®æƒ³æ³•ï¼šä½ ä¸ç”¨å‘Šè¯‰æˆ‘ä¸ºä»€ä¹ˆä¸å¯è¡Œï¼Œä¸ºä»€ä¹ˆæ²¡æ„ä¹‰ï¼Œä¸ºä»€ä¹ˆä¸å¯èƒ½åšåˆ°ï¼Œå°¤å…¶ä¸è¦å†™å‡ ç™¾å­—çš„å°ä½œæ–‡æ¥ï¼Œæˆ‘ä¸æƒ³çœ‹ï¼Œæˆ‘åˆæ²¡æœ‰é‚€è¯·ä½ æ¥å’Œæˆ‘è®¨è®ºï¼Œè¯·æ±‚ä½ ç»™å‡ºè‡ªå·±çš„è§‚ç‚¹ã€‚å¤§å¤šæ•°çš„äº‹æƒ…åœ¨å¤§å¤šæ•°æ—¶å€™éƒ½ä¸å¯è¡Œï¼Œä¸éœ€è¦ä»»ä½•äººæ¥è®ºè¯è¿™ä»¶äº‹ï¼Œæ›´ä¸éœ€è¦è°æ¥å‘ŠçŸ¥æˆ‘ã€‚ä½ ä¸æƒ³åšï¼Œä¸éœ€è¦å¾æ±‚æˆ‘çš„åŒæ„ï¼Œä¹Ÿæ— éœ€å–å¾—æˆ‘çš„è®¤å¯ï¼Œé‚£æ˜¯ä½ è‡ªå·±çš„äº‹ï¼Œä½ è‡ªå·±çš„å†³å®šï¼Œä¸éœ€è¦ç¬¬äºŒä¸ªäººåšè§è¯ã€‚
>
> åŸºäºè¿™ç§æƒ³æ³•ï¼Œæˆ‘è®¤ä¸ºæœ€ä¸äº†èµ·çš„ä¸ªäººèƒ½åŠ›å°±æ˜¯æƒ³åˆ°äº†å°±åŠ¨æ‰‹å»åšã€‚ä¸€ä¸ªäººéƒ½ä¸éœ€è¦ä»€ä¹ˆæ›´é«˜é˜¶æ›´å¼ºå¤§çš„èƒ½åŠ›ï¼Œå•æœ‰è¿™ä¸€é¡¹èƒ½åŠ›å°±å·²ç»è¶…è¿‡äº†äººç¾¤ä¸­ 90% ä»¥ä¸Šçš„äººå£ã€‚å½“æˆ‘ä»¬è¦è®¨è®ºæå‡åŸ¹å…»ä¸ªäººèƒ½åŠ›ï¼Œè®¨è®ºé¡¹ç›®å¯è¡Œæ€§çš„æ—¶å€™ï¼Œåº”è¯¥æ˜¯åœ¨è¿™ 10% çš„äººå£è¿›è¡Œå†…éƒ¨è®¨è®ºã€‚

## [è¿ä¸ªé»„ç½‘éƒ½æ‰¾ä¸åˆ°ï¼Œä½ è¿˜èƒ½å¹²ä»€ä¹ˆï¼Ÿ](https://blog.mynook.info/post/what-else-could-you-do-if-you-cant-even-find-an-adult-site/)

> ç”Ÿå­˜å’Œç¹è¡ï¼Œè¿™æ˜¯ä»»ä½•ç”Ÿç‰©ç§ç¾¤æœ€ä¸ºé¡½å›ºå’Œå¼ºå¤§çš„éœ€æ±‚ã€‚è‡ªäººç±»å‘æ˜é¿å­•å¥—ä¹‹åï¼Œç¹è¡å·²ç»ä¸å†æ˜¯é‡ç‚¹ï¼Œæ€§æˆä¸ºäº†ä¸€ç§å¨±ä¹ã€‚å³ä¾¿å¦‚æ­¤ï¼Œå®ƒçš„é©±åŠ¨ åŠ›ä¹Ÿä¾ç„¶å¼‚å¸¸å¼ºå¤§ã€‚åœ¨æˆ‘çœ‹æ¥ï¼ŒåŠ›å¿…å¤šæ˜¯å¦å¼ºåŠ²æœ‰åŠ›ï¼Œè¡¨å¾ç€ç”Ÿå‘½åŠ›æ˜¯å¦ä¾ç„¶æ—ºç››ã€‚å¦‚æœè¿™ç‚¹å¿ƒæ€éƒ½æ²¡æœ‰äº†ï¼Œå¾ˆéš¾ç›¸ä¿¡è¿™ä¸ªäººè¿˜èƒ½åšå‡ºç‚¹åˆ«çš„ä»€ä¹ˆæ¥ã€‚

> ç›¸é€¢çš„äººæ€»èƒ½ç›¸é€¢ã€‚è¿™æ— éæ˜¯å› ä¸ºæ‰€æœ‰æœ€ç»ˆèƒ½å¤Ÿç›¸é€¢çš„äººéƒ½å…·å¤‡ç›¸åŒçš„äººç”Ÿæ€åº¦ï¼Œæ•…è€Œæœ‰ç›¸åŒçš„è¡ŒåŠ¨èƒ½åŠ›ï¼Œæœ€ ç»ˆä¹Ÿå°±æ€»èƒ½æˆä¸ºå¹¸ç¦çš„å°‘æ•°äººã€‚
